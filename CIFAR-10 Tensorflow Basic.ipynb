{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10\n",
    "\n",
    "Link: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Preparing the Dataset\n",
    "The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with Pickle.\n",
    "\n",
    "Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "- data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "- labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the dataset file names\n",
    "filenames_train = np.array(glob.glob(\"./cifar-10-batches-py/data_batch_*\"), dtype=str)\n",
    "filename_test = \"./cifar-10-batches-py/test_batch\"\n",
    "filename_label = \"./cifar-10-batches-py/batches.meta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['./cifar-10-batches-py/data_batch_2',\n",
       "        './cifar-10-batches-py/data_batch_1',\n",
       "        './cifar-10-batches-py/data_batch_5',\n",
       "        './cifar-10-batches-py/data_batch_4',\n",
       "        './cifar-10-batches-py/data_batch_3'], dtype='<U34'),\n",
       " './cifar-10-batches-py/test_batch',\n",
       " './cifar-10-batches-py/batches.meta')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_train, filename_test, filename_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle the data and return the dictionary containing the data and label\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as f:\n",
    "        dict = pickle.load(f, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames_train:\n",
    "    cifar = unpickle(file)\n",
    "    train_images.extend(cifar[b'data'])\n",
    "    labels += cifar[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(train_images, dtype=float)\n",
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_train = np.array(labels).reshape(-1,1)\n",
    "y_train = np.zeros((50000,10))\n",
    "for i in range(50000):\n",
    "    y_train[i][_y_train[i]] = 1\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 44.,  49.,  53.],\n",
       "         [ 54.,  52.,  52.],\n",
       "         [ 52.,  52.,  51.],\n",
       "         ...,\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.]],\n",
       " \n",
       "        [[ 56.,  59.,  61.],\n",
       "         [ 63.,  64.,  63.],\n",
       "         [ 63.,  59.,  65.],\n",
       "         ...,\n",
       "         [234., 253., 255.],\n",
       "         [255., 254., 253.],\n",
       "         [253., 255., 255.]],\n",
       " \n",
       "        [[ 12.,  14.,  15.],\n",
       "         [ 18.,  23.,  25.],\n",
       "         [ 31.,  41.,  51.],\n",
       "         ...,\n",
       "         [ 23.,  22.,  17.],\n",
       "         [ 18.,  30.,  64.],\n",
       "         [120., 176., 215.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21.,  14.,   8.],\n",
       "         [  9.,  28.,  36.],\n",
       "         [ 52.,  81.,  52.],\n",
       "         ...,\n",
       "         [ 75.,  45.,  93.],\n",
       "         [ 59.,  39.,  35.],\n",
       "         [ 43.,  46.,  48.]],\n",
       " \n",
       "        [[  9.,   8.,   8.],\n",
       "         [  9.,  12.,  13.],\n",
       "         [ 18.,  21.,  16.],\n",
       "         ...,\n",
       "         [ 45.,  44.,  80.],\n",
       "         [102.,  73.,  45.],\n",
       "         [ 45.,  30.,  29.]],\n",
       " \n",
       "        [[  9.,  16.,  15.],\n",
       "         [  8.,  10.,  11.],\n",
       "         [ 10.,  11.,  11.],\n",
       "         ...,\n",
       "         [ 35.,  30.,  55.],\n",
       "         [ 45.,  52.,  35.],\n",
       "         [ 33.,  36.,  37.]]]),\n",
       " array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[94], y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = unpickle(filename_test)\n",
    "test_images = cifar[b'data']\n",
    "test_labels = cifar[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(test_images, dtype=float)\n",
    "X_test = X_test.reshape(-1, 32, 32, 3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_test = np.array(test_labels).reshape(-1,1)\n",
    "y_test = np.zeros((10000,10))\n",
    "for i in range(10000):\n",
    "    y_test[i][_y_test[i]] = 1\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 63.,  58.,  71.],\n",
       "         [ 86.,  86.,  87.],\n",
       "         [ 88.,  87.,  93.],\n",
       "         ...,\n",
       "         [ 88.,  69.,  77.],\n",
       "         [ 73.,  74.,  79.],\n",
       "         [ 80.,  83.,  80.]],\n",
       " \n",
       "        [[ 78.,  73.,  87.],\n",
       "         [ 90., 110., 111.],\n",
       "         [ 93.,  89.,  94.],\n",
       "         ...,\n",
       "         [129.,  99.,  99.],\n",
       "         [ 80.,  82.,  91.],\n",
       "         [ 79.,  77.,  83.]],\n",
       " \n",
       "        [[ 90.,  83.,  78.],\n",
       "         [ 97., 104., 107.],\n",
       "         [104., 110.,  95.],\n",
       "         ...,\n",
       "         [126.,  95.,  82.],\n",
       "         [ 77.,  64.,  79.],\n",
       "         [ 73.,  82.,  93.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 44.,  41.,  52.],\n",
       "         [ 51.,  55.,  52.],\n",
       "         [ 57.,  51.,  48.],\n",
       "         ...,\n",
       "         [ 92.,  56.,  63.],\n",
       "         [ 66.,  70.,  73.],\n",
       "         [ 67.,  67.,  64.]],\n",
       " \n",
       "        [[ 50.,  55.,  58.],\n",
       "         [ 58.,  49.,  55.],\n",
       "         [ 54.,  54.,  56.],\n",
       "         ...,\n",
       "         [ 64.,  69.,  64.],\n",
       "         [ 68.,  67.,  67.],\n",
       "         [ 71.,  73.,  76.]],\n",
       " \n",
       "        [[ 53.,  50.,  50.],\n",
       "         [ 52.,  54.,  54.],\n",
       "         [ 54.,  54.,  60.],\n",
       "         ...,\n",
       "         [ 74.,  74.,  67.],\n",
       "         [ 69.,  69.,  63.],\n",
       "         [ 61.,  64.,  66.]]]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[94], y_test[94]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tensorflow Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 512\n",
    "buffer_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the image parser function\n",
    "def _parser_function(image, label):\n",
    "    image_norm = tf.divide(image, tf.convert_to_tensor(255.0, dtype=tf.float64))\n",
    "    return image_norm, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input pipeline using tf.data\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "dataset = dataset.apply(tf.contrib.data.map_and_batch(map_func=_parser_function, batch_size=n_batch))\n",
    "iterator = dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch iterators\n",
    "input_mini_batch, label_mini_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test pipeline using tf.data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=buffer_size)\n",
    "test_dataset = test_dataset.apply(tf.contrib.data.map_and_batch(map_func=_parser_function, batch_size=n_batch))\n",
    "test_iterator = test_dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch iterators\n",
    "X_test_mini_batch, y_test_mini_batch = test_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN Model\n",
    "We'll use a simple 2 layered CNN model for this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weights and biases with a small amount of noise\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution and pooling layers\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define weights and biases\n",
    "W_conv1 = weight_variable([5,5,3,64])\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "W_conv2 = weight_variable([5,5,64,128])\n",
    "b_conv2 = bias_variable([128])\n",
    "\n",
    "# fully connected layers\n",
    "W_fc1 = weight_variable([8192,2048])\n",
    "b_fc1 = bias_variable([2048])\n",
    "\n",
    "W_fc2 = weight_variable([2048,1024])\n",
    "b_fc2 = bias_variable([1024])\n",
    "\n",
    "W_fc3 = weight_variable([1024,10])\n",
    "b_fc3 = bias_variable([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_1:0\", shape=(?, 8, 8, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# create CNN tensorflow model\n",
    "conv1 = conv2d(X, W_conv1)\n",
    "conv1_activated = tf.nn.relu(conv1 + b_conv1)\n",
    "conv1_maxpool = max_pool_2x2(conv1_activated)\n",
    "\n",
    "conv2 = conv2d(conv1_maxpool, W_conv2)\n",
    "conv2_activated = tf.nn.relu(conv2 + b_conv2)\n",
    "conv2_maxpool = max_pool_2x2(conv2_activated)\n",
    "print(conv2_maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten output from conv layers\n",
    "x_fc = tf.reshape(conv2_maxpool, shape=[-1, 8*8*128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully conected layer 1\n",
    "fc1 = tf.add(tf.matmul(x_fc, W_fc1), b_fc1)\n",
    "fc1_activated = tf.nn.relu(fc1)\n",
    "\n",
    "# fully conected layer 2\n",
    "fc2 = tf.add(tf.matmul(fc1_activated, W_fc2), b_fc2)\n",
    "fc2_activated = tf.nn.relu(fc2)\n",
    "\n",
    "# fully conected layer 3\n",
    "y = tf.add(tf.matmul(fc2_activated, W_fc3), b_fc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "We'll use softmax as our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "We'll use Adam Optimizer for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's minimize the cost using our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optim.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup graph to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a boolean array\n",
    "predictions = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the boolean array to float and calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(predictions, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tensorflow graph\n",
    "init the tensorflow session and create train graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tensorflow interactive session#\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables inside the graph\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Graph"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load graph\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"./model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph(epoch):\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./model_epoch_final.ckpt\", global_step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function to calculate accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy():\n",
    "    # reset iterators\n",
    "    sess.run(iterator.initializer)\n",
    "    sess.run(test_iterator.initializer)\n",
    "    \n",
    "    train_acc = 0\n",
    "    train_iters = 0\n",
    "    \n",
    "    # check train accuracy over 5 mini batches, to reduce computation\n",
    "    for _ in range(10):\n",
    "        train_iters += 1\n",
    "        X_test, y_test = sess.run([input_mini_batch, label_mini_batch])\n",
    "        train_acc += sess.run(accuracy, feed_dict={X: X_test, y_: y_test})\n",
    "\n",
    "    test_acc = 0\n",
    "    test_iters = 0\n",
    "    while True:\n",
    "        try:\n",
    "            test_iters += 1\n",
    "            X_test, y_test = sess.run([X_test_mini_batch, y_test_mini_batch])\n",
    "            test_acc += sess.run(accuracy, feed_dict={X: X_test, y_: y_test})\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    \n",
    "    # print accuracy\n",
    "    print(f\"Train accuracy: {train_acc/train_iters}\")\n",
    "    print(f\"Test accuracy: {test_acc/test_iters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally it's time to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 out of 20, loss: 2288.2527174949646\n",
      "Train accuracy: 0.3759765625\n",
      "Test accuracy: 0.3746170344806853\n",
      "Epoch 1 out of 20, loss: 160.12545669078827\n",
      "Train accuracy: 0.4396484375\n",
      "Test accuracy: 0.40953803346270606\n",
      "Epoch 2 out of 20, loss: 145.02647006511688\n",
      "Train accuracy: 0.4673828125\n",
      "Test accuracy: 0.42655265189352487\n",
      "Epoch 3 out of 20, loss: 133.72713243961334\n",
      "Train accuracy: 0.51875\n",
      "Test accuracy: 0.4630000435170673\n",
      "Epoch 4 out of 20, loss: 122.69937062263489\n",
      "Train accuracy: 0.5728515625\n",
      "Test accuracy: 0.47446712993440177\n",
      "Epoch 5 out of 20, loss: 111.85386765003204\n",
      "Train accuracy: 0.5755859375\n",
      "Test accuracy: 0.47396927504312425\n",
      "Epoch 6 out of 20, loss: 102.22189277410507\n",
      "Train accuracy: 0.628125\n",
      "Test accuracy: 0.48428199404761907\n",
      "Epoch 7 out of 20, loss: 91.28321427106857\n",
      "Train accuracy: 0.6595703125\n",
      "Test accuracy: 0.496618960584913\n",
      "Epoch 8 out of 20, loss: 83.03079849481583\n",
      "Train accuracy: 0.664453125\n",
      "Test accuracy: 0.48397015106110347\n",
      "Epoch 9 out of 20, loss: 75.16708439588547\n",
      "Train accuracy: 0.6748046875\n",
      "Test accuracy: 0.48601081115858896\n",
      "Epoch 10 out of 20, loss: 69.59359043836594\n",
      "Train accuracy: 0.69453125\n",
      "Test accuracy: 0.48634453898384455\n",
      "Epoch 11 out of 20, loss: 64.12923064827919\n",
      "Train accuracy: 0.7044921875\n",
      "Test accuracy: 0.491487219220116\n",
      "Epoch 12 out of 20, loss: 56.05319902300835\n",
      "Train accuracy: 0.7115234375\n",
      "Test accuracy: 0.49417345012937275\n",
      "Epoch 13 out of 20, loss: 51.67589125037193\n",
      "Train accuracy: 0.7751953125\n",
      "Test accuracy: 0.5002680761473519\n",
      "Epoch 14 out of 20, loss: 45.1083667576313\n",
      "Train accuracy: 0.7986328125\n",
      "Test accuracy: 0.5014826229640416\n",
      "Epoch 15 out of 20, loss: 40.457544803619385\n",
      "Train accuracy: 0.8142578125\n",
      "Test accuracy: 0.4972754716873169\n",
      "Epoch 16 out of 20, loss: 35.92724907398224\n",
      "Train accuracy: 0.7947265625\n",
      "Test accuracy: 0.4889596473603022\n",
      "Epoch 17 out of 20, loss: 31.726401537656784\n",
      "Train accuracy: 0.8275390625\n",
      "Test accuracy: 0.49419533496811274\n",
      "Epoch 18 out of 20, loss: 26.538071855902672\n",
      "Train accuracy: 0.855859375\n",
      "Test accuracy: 0.48980764264152166\n",
      "Epoch 19 out of 20, loss: 23.524368047714233\n",
      "Train accuracy: 0.8744140625\n",
      "Test accuracy: 0.49532781896137057\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,n_epochs):\n",
    "    epoch_loss = 0\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            X_for_train, y_for_train = sess.run([input_mini_batch, label_mini_batch])\n",
    "            t, c = sess.run([train, cost], feed_dict={X: X_for_train, y_: y_for_train})\n",
    "            epoch_loss += c\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # print loss\n",
    "    print(f\"Epoch {epoch} out of {n_epochs}, loss: {epoch_loss}\")\n",
    "    \n",
    "    # print train and test accuracies\n",
    "    calculate_accuracy()\n",
    "    \n",
    "    # Save Graph\n",
    "    if epoch % 10 == 0 and epoch >= 2:\n",
    "        save_graph(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
